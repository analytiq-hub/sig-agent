{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a04e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import base64\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "# Try to import PDF libraries\n",
    "try:\n",
    "    import PyPDF2\n",
    "    PDF_LIBRARY = \"PyPDF2\"\n",
    "except ImportError:\n",
    "    try:\n",
    "        import pypdf\n",
    "        PDF_LIBRARY = \"pypdf\"\n",
    "    except ImportError:\n",
    "        PDF_LIBRARY = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the packages directory to the Python path\n",
    "# In Jupyter notebooks, __file__ is not available, so we use os.getcwd() instead\n",
    "TOP_DIR = pathlib.Path(os.getcwd()).parent.parent.parent.parent\n",
    "PACKAGES_DIR = TOP_DIR / \"packages\"\n",
    "sys.path.append(str(PACKAGES_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f588ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BMDS_BASE_URL = os.environ[\"BMDS_BASE_URL\"]\n",
    "if not BMDS_BASE_URL:\n",
    "    raise ValueError(\"BMDS_BASE_URL is not set\")\n",
    "\n",
    "BMDS_WORKSPACE_TOKEN = os.environ[\"BMDS_WORKSPACE_TOKEN\"]\n",
    "if not BMDS_WORKSPACE_TOKEN:\n",
    "    raise ValueError(\"BMDS_WORKSPACE_TOKEN is not set\")\n",
    "\n",
    "# Get organization ID from environment\n",
    "BMDS_ORG_ID = os.environ.get(\"BMDS_ORG_ID\")\n",
    "if not BMDS_ORG_ID:\n",
    "    raise ValueError(\"BMDS_ORG_ID is not set\")\n",
    "\n",
    "BMDS_AAI_AIS_BATCH_TAG_ID = os.environ.get(\"BMDS_AAI_AIS_BATCH_TAG_ID\")\n",
    "if not BMDS_AAI_AIS_BATCH_TAG_ID:\n",
    "    raise ValueError(\"BMDS_AAI_AIS_BATCH_TAG_ID is not set\")\n",
    "\n",
    "BMDS_AAI_AIS_BATCH_PAGE_TAG_ID = os.environ.get(\"BMDS_AAI_AIS_BATCH_PAGE_TAG_ID\")\n",
    "if not BMDS_AAI_AIS_BATCH_PAGE_TAG_ID:\n",
    "    raise ValueError(\"BMDS_AAI_AIS_BATCH_PAGE_TAG_ID is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docrouter_sdk import DocRouterClient\n",
    "from docrouter_sdk.models.document import ListDocumentsResponse\n",
    "\n",
    "def list_all_documents(client, organization_id, tag_ids=None, name_search=None, metadata_search=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Utility function to fetch all documents using pagination.\n",
    "    The API has a maximum limit of 100, so we need to paginate through all results.\n",
    "    \n",
    "    Args:\n",
    "        client: DocRouterClient instance\n",
    "        organization_id: Organization ID to filter documents by\n",
    "        tag_ids: List of tag IDs to filter by (optional)\n",
    "        name_search: Search term for document names (optional)\n",
    "        metadata_search: Metadata search parameters (optional)\n",
    "        verbose: Whether to print progress information (default: True)\n",
    "    \n",
    "    Returns:\n",
    "        ListDocumentsResponse-like object with all documents\n",
    "    \"\"\"\n",
    "    all_documents = []\n",
    "    skip = 0\n",
    "    limit = 100  # API maximum limit\n",
    "    \n",
    "    while True:\n",
    "        if verbose:\n",
    "            print(f\"Fetching documents (skip={skip}, limit={limit})...\")\n",
    "        \n",
    "        # Make the API call with current pagination parameters\n",
    "        response = client.documents.list(\n",
    "            organization_id=organization_id,\n",
    "            skip=skip,\n",
    "            limit=limit,\n",
    "            tag_ids=tag_ids,\n",
    "            name_search=name_search,\n",
    "            metadata_search=metadata_search\n",
    "        )\n",
    "        \n",
    "        # Add documents from this batch\n",
    "        all_documents.extend(response.documents)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Retrieved {len(response.documents)} documents (total so far: {len(all_documents)})\")\n",
    "        \n",
    "        # If we got fewer documents than the limit, we've reached the end\n",
    "        if len(response.documents) < limit:\n",
    "            break\n",
    "            \n",
    "        # Move to next page\n",
    "        skip += limit\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Completed! Retrieved {len(all_documents)} documents total\")\n",
    "    \n",
    "    # Return a response-like object with all documents\n",
    "    return type('ListDocumentsResponse', (), {\n",
    "        'documents': all_documents,\n",
    "        'total_count': len(all_documents),\n",
    "        'skip': 0,\n",
    "        'limit': len(all_documents)\n",
    "    })()\n",
    "\n",
    "def list_documents_with_pagination(client, organization_id, tag_ids=None, name_search=None, metadata_search=None, page_size=100, max_pages=None):\n",
    "    \"\"\"\n",
    "    Alternative utility function that yields documents page by page for memory efficiency.\n",
    "    Useful when dealing with very large document sets.\n",
    "    \n",
    "    Args:\n",
    "        client: DocRouterClient instance\n",
    "        organization_id: Organization ID to filter documents by\n",
    "        tag_ids: List of tag IDs to filter by (optional)\n",
    "        name_search: Search term for document names (optional)\n",
    "        metadata_search: Metadata search parameters (optional)\n",
    "        page_size: Number of documents per page (max 100, default: 100)\n",
    "        max_pages: Maximum number of pages to fetch (optional, for testing)\n",
    "    \n",
    "    Yields:\n",
    "        List of documents for each page\n",
    "    \"\"\"\n",
    "    skip = 0\n",
    "    page_count = 0\n",
    "    \n",
    "    while True:\n",
    "        if max_pages and page_count >= max_pages:\n",
    "            break\n",
    "            \n",
    "        print(f\"Fetching page {page_count + 1} (skip={skip}, limit={page_size})...\")\n",
    "        \n",
    "        # Make the API call with current pagination parameters\n",
    "        response = client.documents.list(\n",
    "            organization_id=organization_id,\n",
    "            skip=skip,\n",
    "            limit=page_size,\n",
    "            tag_ids=tag_ids,\n",
    "            name_search=name_search,\n",
    "            metadata_search=metadata_search\n",
    "        )\n",
    "        \n",
    "        if not response.documents:\n",
    "            break\n",
    "            \n",
    "        yield response.documents\n",
    "        \n",
    "        # If we got fewer documents than the page size, we've reached the end\n",
    "        if len(response.documents) < page_size:\n",
    "            break\n",
    "            \n",
    "        # Move to next page\n",
    "        skip += page_size\n",
    "        page_count += 1\n",
    "    \n",
    "    print(f\"Completed pagination! Processed {page_count + 1} pages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9131f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = DocRouterClient(\n",
    "        base_url=BMDS_BASE_URL,\n",
    "        api_token=BMDS_WORKSPACE_TOKEN\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a8b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAIAIS_PDF=\"/Users/andrei/Documents/Analytiq/Customers/BMDS/data/AAIAIS20210512.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the PDF file and split into pages\n",
    "def split_pdf_into_pages(pdf_path, output_dir):\n",
    "    \"\"\"Split a PDF file into individual pages and return list of page data\"\"\"\n",
    "    pages_data = []\n",
    "    \n",
    "    # Check if file exists and is readable\n",
    "    if not os.path.exists(pdf_path):\n",
    "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
    "    \n",
    "    if not os.access(pdf_path, os.R_OK):\n",
    "        raise PermissionError(f\"Permission denied: Cannot read {pdf_path}\")\n",
    "    \n",
    "    print(f\"Reading PDF file: {pdf_path}\")\n",
    "    print(f\"File size: {os.path.getsize(pdf_path)} bytes\")\n",
    "    \n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            \n",
    "            print(f\"Found {num_pages} pages in PDF\")\n",
    "            \n",
    "            for page_num in range(num_pages):\n",
    "                # Create a new PDF writer for this page\n",
    "                pdf_writer = PyPDF2.PdfWriter()\n",
    "                pdf_writer.add_page(pdf_reader.pages[page_num])\n",
    "                \n",
    "                # Create page filename\n",
    "                page_filename = f\"AAIAIS_page_{page_num + 1:03d}.pdf\"\n",
    "                page_path = output_dir / page_filename\n",
    "                \n",
    "                # Write the page to a file\n",
    "                with open(page_path, 'wb') as output_file:\n",
    "                    pdf_writer.write(output_file)\n",
    "                \n",
    "                # Read the page data for upload\n",
    "                with open(page_path, 'rb') as page_file:\n",
    "                    page_data = page_file.read()\n",
    "                \n",
    "                pages_data.append({\n",
    "                    'filename': page_filename,\n",
    "                    'path': page_path,\n",
    "                    'data': page_data,\n",
    "                    'page_number': page_num + 1\n",
    "                })\n",
    "                \n",
    "                print(f\"  Created page {page_num + 1}: {page_filename}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF file: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return pages_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe2992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory\n",
    "output_dir = pathlib.Path(\"/Users/andrei/Documents/Analytiq/Customers/BMDS/data/output\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Reading PDF file: {AAIAIS_PDF}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Split the PDF into pages\n",
    "pages_data = split_pdf_into_pages(AAIAIS_PDF, output_dir)\n",
    "\n",
    "print(f\"\\nCompleted! Created {len(pages_data)} PDF pages in {output_dir}\")\n",
    "print(f\"Created page files: {[page['filename'] for page in pages_data]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3213e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload PDF pages to workspace (only missing ones)\n",
    "\n",
    "print(\"Checking which PDF pages are already in the workspace...\")\n",
    "\n",
    "# Get current documents in workspace (filtered by the same tag used for uploads)\n",
    "# Use pagination helper to get all documents (API limit is 100)\n",
    "existing_documents = list_all_documents(client, BMDS_ORG_ID, tag_ids=[BMDS_AAI_AIS_BATCH_PAGE_TAG_ID])\n",
    "existing_filenames = {doc.document_name for doc in existing_documents.documents}\n",
    "\n",
    "print(f\"Found {len(existing_filenames)} existing documents in workspace\")\n",
    "print(f\"Existing filenames: {sorted(existing_filenames)}\")\n",
    "\n",
    "# Find PDF pages that need to be uploaded\n",
    "pdf_pages_to_upload = []\n",
    "for page_data in pages_data:\n",
    "    if page_data['filename'] not in existing_filenames:\n",
    "        pdf_pages_to_upload.append(page_data)\n",
    "    else:\n",
    "        print(f\"  ✓ {page_data['filename']} already exists in workspace\")\n",
    "\n",
    "print(f\"\\nPDF pages to upload: {[page['filename'] for page in pdf_pages_to_upload]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdf_pages_to_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload missing PDF pages one by one\n",
    "if pdf_pages_to_upload:\n",
    "    print(f\"\\nUploading {len(pdf_pages_to_upload)} PDF pages individually...\")\n",
    "    \n",
    "    uploaded_documents = []\n",
    "    failed_uploads = []\n",
    "    \n",
    "    for i, page_data in enumerate(pdf_pages_to_upload, 1):\n",
    "        try:\n",
    "            print(f\"\\n[{i}/{len(pdf_pages_to_upload)}] Uploading {page_data['filename']}...\")\n",
    "            \n",
    "            # Encode PDF data as base64\n",
    "            pdf_base64 = base64.b64encode(page_data['data']).decode()\n",
    "            \n",
    "            # Create document data for single upload\n",
    "            document_data = {\n",
    "                \"name\": page_data['filename'],\n",
    "                \"content\": f\"data:application/pdf;base64,{pdf_base64}\",\n",
    "                \"tag_ids\": [BMDS_AAI_AIS_BATCH_PAGE_TAG_ID],\n",
    "                \"metadata\": {\n",
    "                    \"source\": \"aaiais_pdf_split\",\n",
    "                    \"original_document\": os.path.basename(AAIAIS_PDF),\n",
    "                    \"page_number\": str(page_data['page_number']),\n",
    "                    \"total_pages\": str(len(pages_data))\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Upload single document\n",
    "            upload_result = client.documents.upload(BMDS_ORG_ID, [document_data])\n",
    "            \n",
    "            if upload_result and 'documents' in upload_result and len(upload_result['documents']) > 0:\n",
    "                doc = upload_result['documents'][0]\n",
    "                uploaded_documents.append(doc)\n",
    "                print(f\"  ✓ Successfully uploaded {doc['document_name']} (ID: {doc['document_id']})\")\n",
    "            else:\n",
    "                failed_uploads.append({\n",
    "                    'filename': page_data['filename'],\n",
    "                    'error': 'No document returned from upload'\n",
    "                })\n",
    "                print(f\"  ✗ Failed to upload {page_data['filename']}: No document returned\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            failed_uploads.append({\n",
    "                'filename': page_data['filename'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "            print(f\"  ✗ Failed to upload {page_data['filename']}: {str(e)}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(f\"UPLOAD SUMMARY\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Total pages to upload: {len(pdf_pages_to_upload)}\")\n",
    "    print(f\"Successfully uploaded: {len(uploaded_documents)}\")\n",
    "    print(f\"Failed uploads: {len(failed_uploads)}\")\n",
    "    \n",
    "    if uploaded_documents:\n",
    "        print(f\"\\nSuccessfully uploaded documents:\")\n",
    "        for doc in uploaded_documents:\n",
    "            print(f\"  - {doc['document_name']} (ID: {doc['document_id']})\")\n",
    "    \n",
    "    if failed_uploads:\n",
    "        print(f\"\\nFailed uploads:\")\n",
    "        for failed in failed_uploads:\n",
    "            print(f\"  - {failed['filename']}: {failed['error']}\")\n",
    "            \n",
    "else:\n",
    "    print(\"\\nAll PDF pages are already in the workspace - no upload needed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746142e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List documents in the BMDS workspace (filtered by the same tag used for uploads)\n",
    "print(\"Listing documents in BMDS workspace...\")\n",
    "# Use pagination helper to get all documents (API limit is 100)\n",
    "documents = list_all_documents(client, BMDS_ORG_ID, tag_ids=[BMDS_AAI_AIS_BATCH_PAGE_TAG_ID])\n",
    "\n",
    "print(f\"Found {documents.total_count} documents\")\n",
    "print(\"\\nDocument details:\")\n",
    "for i, doc in enumerate(documents.documents, 1):\n",
    "    print(f\"{i}. ID: {doc.id}\")\n",
    "    print(f\"   Name: {doc.document_name}\")\n",
    "    print(f\"   Uploaded: {doc.upload_date}\")\n",
    "    print(f\"   Uploaded by: {doc.uploaded_by}\")\n",
    "    print(f\"   State: {doc.state}\")\n",
    "    print(f\"   Tag IDs: {doc.tag_ids}\")\n",
    "    if doc.metadata:\n",
    "        print(f\"   Metadata: {doc.metadata}\")\n",
    "    print()\n",
    "\n",
    "# Show summary of AAIAIS pages\n",
    "aaiais_pages = [doc for doc in documents.documents if doc.document_name.startswith(\"AAIAIS_page_\")]\n",
    "if aaiiais_pages:\n",
    "    print(f\"\\nAAIAIS PDF Pages Summary:\")\n",
    "    print(f\"Total AAIAIS pages in workspace: {len(aaiiais_pages)}\")\n",
    "    print(\"Page numbers:\", sorted([int(doc.document_name.split('_')[-1].split('.')[0]) for doc in aaiiais_pages]))\n",
    "else:\n",
    "    print(\"\\nNo AAIAIS pages found in workspace.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
